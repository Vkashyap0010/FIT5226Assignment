{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2024 NVIDIA Corporation\n",
      "Built on Thu_Jun__6_03:03:05_Pacific_Daylight_Time_2024\n",
      "Cuda compilation tools, release 12.5, V12.5.82\n",
      "Build cuda_12.5.r12.5/compiler.34385749_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version\n",
    "# import torch\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Grid:\n",
    "    def __init__(self, n=5):\n",
    "        # Parameters\n",
    "        self.n = n  # Grid size n x n\n",
    "        self.actions = ['up', 'right', 'down', 'left']  # Actions the agent can take\n",
    "        self.action_space = len(self.actions)\n",
    "        self.B = (n - 1, n - 1) # Define the target location (B)\n",
    "        \n",
    "        # Initialize Q-table: (agent_row, agent_col, package_row, package_col, carrying_flag, action) \n",
    "        self.q_values = np.zeros((n, n, n, n, 2, self.action_space))\n",
    "    \n",
    "    # Function to check if the state is terminal (i.e., package delivered)\n",
    "    def is_terminal_state(self, agent_row, agent_col, carrying):\n",
    "        return (agent_row, agent_col) == self.B and carrying\n",
    "    \n",
    "    # Function to choose a random, non-terminal starting location for the agent and package\n",
    "    def get_starting_locations(self):\n",
    "        agent_row = np.random.randint(self.n)\n",
    "        agent_col = np.random.randint(self.n)\n",
    "        package_row = np.random.randint(self.n)\n",
    "        package_col = np.random.randint(self.n)\n",
    "        while (agent_row, agent_col) == self.B or (package_row, package_col) == self.B:\n",
    "            agent_row = np.random.randint(self.n)\n",
    "            package_row = np.random.randint(self.n)\n",
    "            package_col = np.random.randint(self.n)\n",
    "        return agent_row, agent_col, package_row, package_col\n",
    "\n",
    "    # Function to get the next location based on the chosen action\n",
    "    def get_next_location(self, agent_row, agent_col, action_index):\n",
    "        new_row, new_col = agent_row, agent_col\n",
    "        if self.actions[action_index] == 'up' and agent_row > 0:\n",
    "            new_row -= 1\n",
    "        elif self.actions[action_index] == 'right' and agent_col < self.n - 1:\n",
    "            new_col += 1\n",
    "        elif self.actions[action_index] == 'down' and agent_row < self.n - 1:\n",
    "            new_row += 1\n",
    "        elif self.actions[action_index] == 'left' and agent_col > 0:\n",
    "            new_col -= 1\n",
    "        return new_row, new_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearningAgent:\n",
    "    def __init__(self, grid_env, epsilon=0.9, discount_factor=0.9, learning_rate=0.1):\n",
    "        # Epsilon-greedy algorithm for choosing the next action\n",
    "        self.grid_env = grid_env \n",
    "        self.epsilon = epsilon # Epsilon for epsilon-greedy strategy\n",
    "        self.discount_factor = discount_factor # Discount factor for future rewards\n",
    "        self.learning_rate = learning_rate  # Learning rate\n",
    "    \n",
    "    # Epsilon-greedy algorithm for choosing the next action\n",
    "    def get_next_action(self, agent_row, agent_col, package_row, package_col, carrying):\n",
    "        if np.random.random() < self.epsilon:\n",
    "            return np.argmax(self.grid_env.q_values[agent_row, agent_col, package_row, package_col, carrying])\n",
    "        else:\n",
    "            return np.random.randint(self.grid_env.action_space)\n",
    "    \n",
    "    # Function to update the Q-values during training\n",
    "    def update_q_values(self, old_state, action_index, reward, new_state):\n",
    "        old_q_value = self.grid_env.q_values[old_state][action_index]\n",
    "        temporal_difference = reward + (self.discount_factor * np.max(self.grid_env.q_values[new_state])) - old_q_value\n",
    "        self.grid_env.q_values[old_state][action_index] = old_q_value + (self.learning_rate * temporal_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearningTraining:\n",
    "    def __init__(self, grid_env, agent, num_episodes=100000, max_steps_per_episode=200):\n",
    "        self.grid_env = grid_env\n",
    "        self.agent = agent\n",
    "        # Training parameters\n",
    "        self.num_episodes = num_episodes # Number of training episodes\n",
    "        self.max_steps_per_episode = max_steps_per_episode # Limit the steps per episode\n",
    "    \n",
    "    def train(self):\n",
    "        # Training loop\n",
    "        for episode in range(self.num_episodes):\n",
    "            \n",
    "            # Initialize starting locations\n",
    "            agent_row, agent_col, package_row, package_col = self.grid_env.get_starting_locations()\n",
    "            carrying = 0  # Agent starts without carrying the package\n",
    "            \n",
    "            for step in range(self.max_steps_per_episode):\n",
    "                \n",
    "                # Choose action\n",
    "                action_index = self.agent.get_next_action(agent_row, agent_col, package_row, package_col, carrying)\n",
    "                \n",
    "                # Get next location\n",
    "                new_agent_row, new_agent_col = self.grid_env.get_next_location(agent_row, agent_col, action_index)\n",
    "                \n",
    "                # Determine the reward and update carrying status\n",
    "                if (new_agent_row, new_agent_col) == (package_row, package_col) and not carrying:\n",
    "                    reward = 20  # pickup_reward\n",
    "                    carrying = 1  # Now the agent is carrying the package\n",
    "                elif (new_agent_row, new_agent_col) == self.grid_env.B and carrying:\n",
    "                    reward = 80  # delivery_reward\n",
    "                else:\n",
    "                    reward = -1  # move_reward\n",
    "                \n",
    "                # Update Q-values\n",
    "                old_state = (agent_row, agent_col, package_row, package_col, carrying)\n",
    "                new_state = (new_agent_row, new_agent_col, package_row, package_col, carrying)\n",
    "                self.agent.update_q_values(old_state, action_index, reward, new_state)\n",
    "                \n",
    "                # Transition to the new state\n",
    "                agent_row, agent_col = new_agent_row, new_agent_col\n",
    "                \n",
    "                # Check if the task is complete\n",
    "                if self.grid_env.is_terminal_state(agent_row, agent_col, carrying):\n",
    "                    break\n",
    "        \n",
    "        print('Training complete!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the agent's performance after training\n",
    "class QLearningTester:\n",
    "    def __init__(self, grid_env, agent, max_steps_per_episode=200):\n",
    "        self.grid_env = grid_env\n",
    "        self.agent = agent\n",
    "        self.max_steps_per_episode = max_steps_per_episode\n",
    "    \n",
    "    def test(self, num_tests=10):\n",
    "        success_count = 0\n",
    "        for _ in range(num_tests):\n",
    "            agent_row, agent_col, package_row, package_col = self.grid_env.get_starting_locations()\n",
    "            carrying = 0\n",
    "            path = [(agent_row, agent_col)]\n",
    "            for step in range(self.max_steps_per_episode):\n",
    "                action_index = self.agent.get_next_action(agent_row, agent_col, package_row, package_col, 1)\n",
    "                agent_row, agent_col = self.grid_env.get_next_location(agent_row, agent_col, action_index)\n",
    "                path.append((agent_row, agent_col))\n",
    "                if (agent_row, agent_col) == (package_row, package_col) and not carrying:\n",
    "                    carrying = 1\n",
    "                if self.grid_env.is_terminal_state(agent_row, agent_col, carrying):\n",
    "                    success_count += 1\n",
    "                    print('Success')\n",
    "                    break\n",
    "            print(f'Path taken by agent for package location: {(package_row, package_col)} - ')\n",
    "            print(path)\n",
    "        print(f'Success rate: {success_count}/{num_tests}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n",
      "Success\n",
      "Path taken by agent for package location: (0, 0) - \n",
      "[(1, 0), (0, 0), (0, 1), (1, 1), (1, 2), (1, 3), (2, 3), (3, 3), (3, 4), (4, 4)]\n",
      "Path taken by agent for package location: (1, 2) - \n",
      "[(3, 2), (3, 3), (3, 4), (4, 4), (3, 4), (4, 4), (4, 3), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (3, 3), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (4, 4), (3, 4), (4, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (4, 3), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (3, 3), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (4, 3), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (4, 4), (3, 4)]\n",
      "Path taken by agent for package location: (3, 3) - \n",
      "[(0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (1, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (1, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 3), (0, 4), (0, 4), (0, 4), (0, 4), (1, 4), (0, 4), (0, 4), (0, 4), (1, 4), (1, 4), (1, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (1, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 3), (0, 4), (0, 4), (0, 4), (0, 4), (0, 4), (0, 3), (0, 4), (0, 4), (0, 4), (0, 4)]\n",
      "Success\n",
      "Path taken by agent for package location: (3, 4) - \n",
      "[(3, 2), (3, 3), (3, 4), (4, 4)]\n",
      "Path taken by agent for package location: (4, 2) - \n",
      "[(3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (4, 3), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (4, 3), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (2, 4), (3, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (4, 3)]\n",
      "Path taken by agent for package location: (0, 0) - \n",
      "[(3, 0), (3, 1), (3, 2), (3, 3), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (4, 4), (3, 4), (3, 4), (3, 3), (3, 2), (3, 3), (3, 4), (4, 4), (3, 4), (3, 3), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (2, 4), (3, 4), (4, 4), (3, 4), (3, 3), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (2, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (2, 4), (3, 4), (4, 4), (3, 4), (4, 4), (4, 3), (3, 3), (3, 4), (3, 3), (3, 4), (3, 3), (3, 4), (4, 4), (3, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (3, 3), (4, 3), (4, 4), (3, 4), (4, 4), (4, 3), (4, 4), (3, 4), (2, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (2, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (2, 4), (2, 3), (3, 3), (3, 4), (4, 4), (3, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4)]\n",
      "Path taken by agent for package location: (1, 4) - \n",
      "[(3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (2, 4), (3, 4), (4, 4), (4, 4), (3, 4), (2, 4), (3, 4), (4, 4), (3, 4), (2, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (3, 3), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (4, 3), (3, 3), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (2, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (4, 4), (3, 4), (4, 4), (3, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (3, 3), (3, 4), (4, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4)]\n",
      "Path taken by agent for package location: (1, 0) - \n",
      "[(1, 2), (1, 1), (2, 1), (3, 1), (3, 2), (3, 3), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (4, 4), (4, 3), (3, 3), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (4, 3), (3, 3), (3, 4), (3, 4), (4, 4), (4, 4), (3, 4), (4, 4), (3, 4), (3, 3), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (4, 3), (3, 3), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (2, 4), (2, 3), (3, 3), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (4, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (4, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (3, 3), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (2, 4), (2, 3), (3, 3), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (4, 4), (4, 3), (3, 3), (3, 4), (4, 4), (3, 4), (4, 4), (4, 3), (3, 3), (3, 4), (4, 4), (3, 4), (3, 4), (4, 4), (3, 4), (4, 4), (3, 4), (2, 4), (2, 3), (3, 3)]\n",
      "Success\n",
      "Path taken by agent for package location: (1, 2) - \n",
      "[(0, 2), (1, 2), (1, 3), (1, 4), (2, 4), (3, 4), (4, 4)]\n",
      "Success\n",
      "Path taken by agent for package location: (3, 2) - \n",
      "[(2, 4), (3, 4), (3, 3), (3, 2), (3, 3), (4, 3), (4, 4)]\n",
      "Success rate: 4/10\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classes and run training/testing\n",
    "grid_env = Grid()\n",
    "agent = QLearningAgent(grid_env)\n",
    "training = QLearningTraining(grid_env, agent)\n",
    "training.train()\n",
    "\n",
    "tester = QLearningTester(grid_env, agent)\n",
    "tester.test()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
