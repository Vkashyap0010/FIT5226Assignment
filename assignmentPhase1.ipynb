{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n = 5  # Grid size n x n\n",
    "actions = ['up', 'right', 'down', 'left']  # Actions the agent can take\n",
    "action_space = len(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Q-table: (agent_row, agent_col, package_row, package_col, carrying_flag, action) \n",
    "q_values = np.random.rand(n, n, n, n, 2, action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewards\n",
    "delivery_reward = 100  \n",
    "move_reward = -1  \n",
    "pickup_reward = 50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target location (B)\n",
    "B = (n - 1, n - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if the state is terminal (i.e., package delivered)\n",
    "def is_terminal_state(agent_row, agent_col, carrying):\n",
    "    return (agent_row, agent_col) == B and carrying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to choose a random, non-terminal starting location for the agent and package\n",
    "def get_starting_locations():\n",
    "    agent_row = np.random.randint(n)\n",
    "    agent_col = np.random.randint(n)\n",
    "    package_row = np.random.randint(n)\n",
    "    package_col = np.random.randint(n)\n",
    "    while (agent_row, agent_col) == B or (package_row, package_col) == B:\n",
    "        agent_row = np.random.randint(n)\n",
    "        package_row = np.random.randint(n)\n",
    "        package_col = np.random.randint(n)\n",
    "    return agent_row, agent_col, package_row, package_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epsilon-greedy algorithm for choosing the next action\n",
    "def get_next_action(agent_row, agent_col, package_row, package_col, carrying, epsilon):\n",
    "    if np.random.random() < epsilon:\n",
    "        return np.argmax(q_values[agent_row, agent_col, package_row, package_col, carrying])\n",
    "    else:\n",
    "        return np.random.randint(action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the next location based on the chosen action\n",
    "def get_next_location(agent_row, agent_col, action_index):\n",
    "    new_row, new_col = agent_row, agent_col\n",
    "    if actions[action_index] == 'up' and agent_row > 0:\n",
    "        new_row -= 1\n",
    "    elif actions[action_index] == 'right' and agent_col < n - 1:\n",
    "        new_col += 1\n",
    "    elif actions[action_index] == 'down' and agent_row < n - 1:\n",
    "        new_row += 1\n",
    "    elif actions[action_index] == 'left' and agent_col > 0:\n",
    "        new_col -= 1\n",
    "    return new_row, new_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update the Q-values during training\n",
    "#alpha - learning_rate, gamma - discount_factor\n",
    "def update_q_values(old_state, action_index, reward, new_state, learning_rate, discount_factor):\n",
    "    old_q_value = q_values[old_state][action_index]\n",
    "    temporal_difference = reward + (discount_factor * np.max(q_values[new_state])) - old_q_value\n",
    "    q_values[old_state][action_index] = old_q_value + (learning_rate * temporal_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "epsilon = 0.9  # Epsilon for epsilon-greedy strategy\n",
    "discount_factor = 0.9  # Discount factor for future rewards\n",
    "learning_rate = 0.9  # Learning rate\n",
    "num_episodes = 100000  # Number of training episodes\n",
    "max_steps_per_episode = 200  # Limit the steps per episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for episode in range(num_episodes):\n",
    "    # Initialize starting locations\n",
    "    agent_row, agent_col, package_row, package_col = get_starting_locations()\n",
    "    carrying = 0  # Agent starts without carrying the package\n",
    "    \n",
    "    for step in range(max_steps_per_episode):\n",
    "        # Choose action\n",
    "        action_index = get_next_action(agent_row, agent_col, package_row, package_col, carrying, epsilon)\n",
    "        \n",
    "        # Get next location\n",
    "        new_agent_row, new_agent_col = get_next_location(agent_row, agent_col, action_index)\n",
    "        \n",
    "        # Determine the reward and update carrying status\n",
    "        if (new_agent_row, new_agent_col) == (package_row, package_col) and not carrying:\n",
    "            reward = pickup_reward\n",
    "            carrying = 1  # Now the agent is carrying the package\n",
    "        elif (new_agent_row, new_agent_col) == B and carrying:\n",
    "            reward = delivery_reward\n",
    "        else:\n",
    "            reward = move_reward\n",
    "        \n",
    "        # Update Q-values\n",
    "        old_state = (agent_row, agent_col, package_row, package_col, carrying)\n",
    "        new_state = (new_agent_row, new_agent_col, package_row, package_col, carrying)\n",
    "        update_q_values(old_state, action_index, reward, new_state, learning_rate, discount_factor)\n",
    "        \n",
    "        # Transition to the new state\n",
    "        agent_row, agent_col = new_agent_row, new_agent_col\n",
    "        \n",
    "        # Check if the task is complete\n",
    "        if is_terminal_state(agent_row, agent_col, carrying):\n",
    "            break\n",
    "    \n",
    "    \n",
    "\n",
    "print('Training complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n",
      "Path taken by agent for package location: (4, 2) - \n",
      "[(0, 3), (1, 3), (2, 3), (3, 3), (4, 3), (4, 2), (4, 3), (4, 4)]\n",
      "Success\n",
      "Path taken by agent for package location: (2, 1) - \n",
      "[(2, 3), (2, 2), (2, 1), (2, 2), (2, 3), (2, 4), (3, 4), (4, 4)]\n",
      "Success\n",
      "Path taken by agent for package location: (1, 2) - \n",
      "[(0, 4), (1, 4), (1, 3), (1, 2), (2, 2), (2, 3), (2, 4), (3, 4), (4, 4)]\n",
      "Success\n",
      "Path taken by agent for package location: (0, 4) - \n",
      "[(1, 3), (0, 3), (0, 4), (1, 4), (2, 4), (3, 4), (4, 4)]\n",
      "Success\n",
      "Path taken by agent for package location: (4, 1) - \n",
      "[(2, 2), (3, 2), (3, 1), (4, 1), (4, 2), (4, 3), (4, 4)]\n",
      "Path taken by agent for package location: (3, 1) - \n",
      "[(3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2)]\n",
      "Success\n",
      "Path taken by agent for package location: (4, 1) - \n",
      "[(2, 3), (3, 3), (3, 2), (3, 1), (4, 1), (4, 2), (4, 3), (4, 4)]\n",
      "Success\n",
      "Path taken by agent for package location: (2, 4) - \n",
      "[(3, 3), (3, 4), (2, 4), (3, 4), (4, 4)]\n",
      "Success\n",
      "Path taken by agent for package location: (0, 3) - \n",
      "[(3, 3), (2, 3), (1, 3), (0, 3), (0, 4), (1, 4), (2, 4), (3, 4), (4, 4)]\n",
      "Success\n",
      "Path taken by agent for package location: (3, 3) - \n",
      "[(3, 0), (3, 1), (3, 2), (3, 3), (3, 4), (4, 4)]\n",
      "Success rate: 9/10\n"
     ]
    }
   ],
   "source": [
    "# Test the agent's performance after training\n",
    "def test_agent(num_tests=10):\n",
    "    success_count = 0\n",
    "    for _ in range(num_tests):\n",
    "        agent_row, agent_col, package_row, package_col = get_starting_locations()\n",
    "        carrying = 0\n",
    "        path = [(agent_row, agent_col)]\n",
    "        for step in range(max_steps_per_episode):\n",
    "            action_index = get_next_action(agent_row, agent_col, package_row, package_col, carrying, 1.0)\n",
    "            agent_row, agent_col = get_next_location(agent_row, agent_col, action_index)\n",
    "            path.append((agent_row, agent_col))\n",
    "            if (agent_row, agent_col) == (package_row, package_col) and not carrying:\n",
    "                carrying = 1\n",
    "            if is_terminal_state(agent_row, agent_col, carrying):\n",
    "                success_count += 1\n",
    "                print('Success')\n",
    "                break\n",
    "        print(f'Path taken by agent for package location: {(package_row, package_col)} - ')\n",
    "        print(path)\n",
    "    print(f'Success rate: {success_count}/{num_tests}')\n",
    "\n",
    "test_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
